bins.wmax.gt.tmin.yn = ifelse(bins.wmax.gt.tmin,"Y", "N")
segments(y0 = yVal,
x0 = bins.wmin,
x1 = bins.wmax,
col=colSpec, lwd=thick)    # recycles col
# Bin break labels (cannot do , with vector for labels, it seems):
for(iiii in 1:length(bins.wmin))
{
text(x = bins.wmin[iiii],
y = yVal,
labels = bquote(paste(w[.(ii)*","*
.(dplyr::filter(dataComb, SpecCode == specForFig[ii])$j[iiii])])),
pos = 1,
offset = 0.03*thick,
cex = cex.sub)
}
# Do final wmax manually:
text(x = bins.wmax[length(bins.wmax)],
y = yVal,
labels = bquote(paste(w[.(ii)*","*
.(max(dplyr::filter(dataComb, SpecCode == specForFig[ii])$j)+1)])),
pos = 1,
offset = 0.03*thick,
cex = cex.sub)
# Put counts for each bin
text(x = bins.wmid,
y = yVal,
labels = f(dplyr::filter(dataComb, SpecCode == specForFig[ii])$number, ii+1),
# ii+1 happens to give 3 d.p.s for species 2 and 2 for species 1,
#  as needed on figure
pos = NULL,
offset = 0.03*thick,
cex = cex.sub*1.2)
# Whether to include in counts
eps = 0.23                  # Offset from wmid for Y's and N's
text(x = bins.wmid - eps,
y = yVal,
labels = bins.wmin.gt.tmax.yn,
pos = 3,
offset = 0.03*thick,
cex = cex.sub*1.2)
text(x = bins.wmid + eps,
y = yVal,
labels = bins.wmax.gt.tmin.yn,
pos = 3,
offset = 0.03*thick,
cex = cex.sub*1.2)
}
# Need w_1,24 manually, assumes this is the only one with j=23
text(x = dplyr::filter(dataComb, j==23)$wmax,
y = yVals[1],
labels = bquote(paste(w[.(1)*","*24])),
pos = 1,
offset = 0.03*thick,
cex = cex.sub)
dataRecommend.isd = dplyr::select(dataBin,
Year,
wmin,
wmax,
Number)
data.year.list = list()                # to save results for each year
diff.ivec = vector()                   # to save i that have any cumSum !=
# verify TODO
fullYears = sort(unique(dataBin$Year))
for(i in 1:length(fullYears))
{
data.year = dplyr::filter(dataRecommend.isd,
Year == fullYears[i])
data.year = dplyr::arrange(data.year,
desc(wmin))
sumNumber = sum(data.year$Number)
# data.year = dplyr::mutate(data.year,
#                          cumSum = cumsum(Number))
# This is wrong when we have two species with the same
#  length-weight coefficients in the same year, use countGTEwmin then change it to
#                          cumSum in one go TODO since clearer
# Have to do not with dplyr:
wmin.vec = data.year$wmin
wmax.vec = data.year$wmax
num.vec  = data.year$Number
countGTEwmin = rep(NA, length(num.vec)) # to do a manual count
lowCount = countGTEwmin
highCount = countGTEwmin
for(iii in 1:length(countGTEwmin))
{
countGTEwmin[iii]    = sum( (wmin.vec >= wmin.vec[iii]) * num.vec)
lowCount[iii]  = sum( (wmin.vec >= wmax.vec[iii]) * num.vec)
highCount[iii] = sum( (wmax.vec >  wmin.vec[iii]) * num.vec)
}
data.year = cbind(data.year,
"countGTEwmin" = countGTEwmin,
"lowCount" = lowCount,
"highCount" = highCount)
data.year = dplyr::tbl_df(data.year)
data.year.list[[i]] = data.year
}
xlim.global = c(min(dataRecommend.isd$wmin),
max(dataRecommend.isd$wmax))   # x-axis limits to be common for
# all plots
ISD_bin_plot()
for(i in 1:length(fullYears))
{
ISD_bin_plot(data.year = data.year.list[[i]],
b.MLE = dplyr::filter(MLEbins.res, Year == fullYears[i])$b,
b.confMin = dplyr::filter(MLEbins.res, Year ==
fullYears[i])$confMin,
b.confMax = dplyr::filter(MLEbins.res, Year ==
fullYears[i])$confMax,
year = fullYears[i],
xlim = xlim.global,
xmin = dplyr::filter(MLEbins.res, Year ==
fullYears[i])$xmin,
xmax = dplyr::filter(MLEbins.res, Year ==
fullYears[i])$xmax
)
}
?ISD_bin_plot
ls()
load("/Users/robins64/Documents/git_repos/sey-nutrition/data/clean/nutrient/sey_nutrient_clean_stirling.Rdata")
ls()
ls()
head(biom.sp)
head(mast)
load("/Users/robins64/Documents/git_repos/fish-indicators/02_curve_fit/data/curve_fit_ready_jarvis.rdata")
ls()
head(biom)
load("/Users/robins64/Documents/git_repos/fish-indicators/01_pre-processing/data/jarvis_spc.biomseTL.yr.rdata")
ls()
head(BIO)
load("/Users/robins64/Documents/git_repos/changing-mpas/results/biomass_model.Rdata")
ls()
ls()
head(catches)
head(packages)
head(packets)
head(trips)
head(species)
packets
ls()
head(results)
head(mgma)
head(mgam)
str(mgam)
str(results)
dbinom(6, 9, 0.5)
dbinom(6, 9, 0.2)
dbinom(6, 9, 0.9)
dbinom(6, 9000, 0.5)
dbinom(6, 6, 0.5)
dbinom(6, 12, 0.5)
dbinom(6, 12, 0.9)
dbinom(6, 12, 0.55)
dbinom(6, 12, 0.5)
# define grid
p_grid <- seq( from=0 , to=1 , length.out=20 )
p_grid
p_grid <- seq( from=0 , to=1 , length.out=20 )
# define prior
prior <- rep( 1 , 20 )
# compute likelihood at each value in grid
likelihood <- dbinom( 6 , size=9 , prob=p_grid )
# compute product of likelihood and prior
unstd.posterior <- likelihood * prior
# standardize the posterior, so it sums to 1
posterior <- unstd.posterior / sum(unstd.posterior)
plot( p_grid , posterior , type="b" ,
xlab="probability of water" , ylab="posterior probability" )
mtext( "20 points" )
p_grid <- seq( from=0 , to=1 , length.out=20 )
# define prior
prior <- rep( 1 , 20 )
# compute likelihood at each value in grid
likelihood <- dbinom( 6 , size=9 , prob=p_grid )
# compute product of likelihood and prior
unstd.posterior <- likelihood * prior
# standardize the posterior, so it sums to 1
posterior <- unstd.posterior / sum(unstd.posterior)
plot( p_grid , posterior , type="b" ,
xlab="probability of water" , ylab="posterior probability" )
mtext( "20 points" )
p_seq
p_grid
prior
dbinom(6, 9, 0.5)
dbinom(6, 9, 0.2)
dbinom(6, 9, 0.9)
6/9
dbinom(6, 9, 1)
dbinom(6, 9, 1)
dbinom(6, 9, prob=0)
6/9
p_grid <- seq( from=0 , to=1 , length.out=1000 )
# define prior
prior <- rep( 1 , 20 )
# compute likelihood at each value in grid
likelihood <- dbinom( 6 , size=9 , prob=p_grid )
# compute product of likelihood and prior
unstd.posterior <- likelihood * prior
# standardize the posterior, so it sums to 1
posterior <- unstd.posterior / sum(unstd.posterior)
plot( p_grid , posterior , type="b" ,
xlab="probability of water" , ylab="posterior probability" )
mtext( "20 points" )
likelihood
# define grid
p_grid <- seq( from=0 , to=1 , length.out=20 )
# define prior
prior <- rep( 1 , 20 )
# compute likelihood at each value in grid
likelihood <- dbinom( 6 , size=9 , prob=p_grid )
likelihood
## quadratic approximation
library(rethinking)
globe.qa <- quap(
alist(
W ~ dbinom( W+L ,p) , # binomial likelihood p ~ dunif(0,1) # uniform prior
), data=list(W=6,L=3) )
globe.qa <- quap(
alist(
W ~ dbinom( W+L ,p) , # binomial likelihood p ~ dunif(0,1) # uniform prior
), data=list(W=6,L=3) )
globe.qa <- quap(
alist(
W ~ dbinom( W+L ,p) , # binomial likelihood p ~ dunif(0,1) # uniform prior
), data=list(W=6,L=3) )
globe.qa <- quap(alist(
W ~ dbinom( W+L ,p) , # binomial likelihood
p ~ dunif(0,1) # uniform prior
), data=list(W=6,L=3) )
precis(globe.qa)
## Chapter2 - small worlds and large worlds
dbinom(6, 9, 0.5)
dbinom(6, 9, 1)
dbinom(6, 9, prob=0)
dbinom(6, 9000, 0.5)
dbinom(6, 6, 0.5)
dbinom(6, 12, 0.5)
## grid approximation
# define grid
p_grid <- seq( from=0 , to=1 , length.out=20 )
# define prior
prior <- rep( 1 , 20 )
for(i in 1:3){
# compute likelihood at each value in grid
if(i == 1){likelihood <- dbinom( 3 , size=3 , prob=p_grid )}
if(i == 2){likelihood <- dbinom( 3 , size=4 , prob=p_grid )}
if(i == 3){likelihood <- dbinom( 5 , size=7 , prob=p_grid )}
# compute product of likelihood and prior
unstd.posterior <- likelihood * prior
# standardize the posterior, so it sums to 1
posterior <- unstd.posterior / sum(unstd.posterior)
plot( p_grid , posterior , type="b" ,
xlab="probability of water" , ylab="posterior probability" , title='i')
}
warnings()
# compute likelihood at each value in grid
if(i == 1){likelihood <- dbinom( 3 , size=3 , prob=p_grid )}
# compute product of likelihood and prior
unstd.posterior <- likelihood * prior
# standardize the posterior, so it sums to 1
posterior <- unstd.posterior / sum(unstd.posterior)
plot( p_grid , posterior , type="b" ,
xlab="probability of water" , ylab="posterior probability" , title='i')
par(mfrow=c(1,3))
for(i in 1:3){
# compute likelihood at each value in grid
if(i == 1){likelihood <- dbinom( 3 , size=3 , prob=p_grid )}
if(i == 2){likelihood <- dbinom( 3 , size=4 , prob=p_grid )}
if(i == 3){likelihood <- dbinom( 5 , size=7 , prob=p_grid )}
# compute product of likelihood and prior
unstd.posterior <- likelihood * prior
# standardize the posterior, so it sums to 1
posterior <- unstd.posterior / sum(unstd.posterior)
plot( p_grid , posterior , type="b" ,
xlab="probability of water" , ylab="posterior probability" , main='i')
}
par(mfrow=c(1,3))
for(i in 1:3){
# compute likelihood at each value in grid
if(i == 1){likelihood <- dbinom( 3 , size=3 , prob=p_grid )}
if(i == 2){likelihood <- dbinom( 3 , size=4 , prob=p_grid )}
if(i == 3){likelihood <- dbinom( 5 , size=7 , prob=p_grid )}
# compute product of likelihood and prior
unstd.posterior <- likelihood * prior
# standardize the posterior, so it sums to 1
posterior <- unstd.posterior / sum(unstd.posterior)
plot( p_grid , posterior , type="b" ,
xlab="probability of water" , ylab="posterior probability" , main=i)
}
## problem 2M2
prior[prior < 0.5] <- 0
prior
## problem 2M2
prior[prior < 0.5] <- 0
prior
prior < 0.5
## problem 2M2
prior[p_grid < 0.5] <- 0
prior
for(i in 1:3){
# compute likelihood at each value in grid
if(i == 1){likelihood <- dbinom( 3 , size=3 , prob=p_grid )}
if(i == 2){likelihood <- dbinom( 3 , size=4 , prob=p_grid )}
if(i == 3){likelihood <- dbinom( 5 , size=7 , prob=p_grid )}
# compute product of likelihood and prior
unstd.posterior <- likelihood * prior
# standardize the posterior, so it sums to 1
posterior <- unstd.posterior / sum(unstd.posterior)
plot( p_grid , posterior , type="b" ,
xlab="probability of water" , ylab="posterior probability" , main=i)
}
setwd('tidytuesday')
library(tidyverse); library(funk)
volcano <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-12/volcano.csv')
eruptions <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-12/eruptions.csv')
events <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-12/events.csv')
head(volcano) %>% data.frame()
head(eruptions) %>% data.frame()
head(events) %>% data.frame()
obs<-eruptions %>% filter(evidence_method_dating == 'Historical Observations' & start_year > 1800) %>%
select(volcano_name, volcano_number, vei, start_year, end_year, latitude, longitude) %>%
group_by(volcano_name) %>% mutate(freq = length(volcano_name), max.vei = max(vei, na.rm=TRUE)) %>%
ungroup()
obs$region<-factor(obs$region)
obs<-left_join(obs, volcano) %>%
mutate(volcano_name = fct_reorder(volcano_name, longitude))
plotter<-obs %>% filter(vei > 3 & freq > 10)
left<-ggplot(plotter, aes(volcano_name, start_year, fill = population_within_10_km, size=vei)) +
geom_point(alpha=0.5, shape=21,colour='black',stroke=1.2) +
coord_flip() +
labs(x='', y='') +
scale_size_area(breaks=c(4,5,6), trans='exp', max_size=30) +
scale_fill_gradient(na.value='white', low='#ffffcc', high='#800026') +
scale_y_continuous(breaks=seq(1800, 2020, 20)) +
scale_x_discrete(expand=c(0.05,0.05)) +
theme_classic() +
theme(legend.position = 'none',
panel.grid.major.y = element_line(),
plot.margin=unit(c(0.5, 0, 0, 0), 'cm'))
plotter2<-plotter %>% group_by(volcano_name, region) %>% summarise(freq = unique(freq))
right<-ggplot(plotter2) +
geom_bar(aes(volcano_name, freq, fill=region), stat='identity') +
geom_text(aes(x=volcano_name, y=freq, label = region, col=region), size=2,hjust = -0.1) +
coord_flip() +
labs(y = 'Number of eruptions since 1800', x = '') +
theme_classic() +
theme(axis.text.y = element_blank(), axis.ticks=element_blank(), legend.position = 'none',
plot.margin=unit(c(0.5, 0, 0, 0), 'cm')) +
scale_y_continuous(expand=c(0, 0), breaks=seq(0, 100, 25)) +
scale_x_discrete(expand=c(0.05,0.05))
cowplot::plot_grid(left, right, rel_widths = c(1, 0.3), nrow=1)
#
# ggplot(obs %>% filter(start_year > 1882 & !is.na(vei)), aes(country, start_year, fill=vei)) +
#           geom_tile() +
#           coord_flip() +
#           theme_bw()
#
# ggplot(obs %>% filter(start_year > 1882 & !is.na(vei)), aes(vei, start_year, group=volcano_name)) +
#   geom_line() +
#   coord_flip() +
#   theme_bw()
#
#
#
# ggplot(obs %>% filter(start_year > 1882 & !is.na(vei)), aes(longitude, latitude, col=start_year, size=vei)) +
#   geom_point(alpha=0.2) +
#   theme_bw()
#
# ggplot(obs, aes(longitude, latitude, col=freq, size=max.vei)) +
#   geom_point(alpha=0.2) +
#   theme_bw()+
#   scale_colour_gradient(high='red', low='white')
#
#
#
#
#
obs<-eruptions %>% filter(evidence_method_dating == 'Historical Observations' & start_year > 1800) %>%
select(volcano_name, volcano_number, vei, start_year, end_year, latitude, longitude) %>%
group_by(volcano_name) %>% mutate(freq = length(volcano_name), max.vei = max(vei, na.rm=TRUE)) %>%
ungroup()
obs$region<-factor(obs$region)
setwd('tidytuesday')
library(tidyverse); library(funk)
volcano <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-12/volcano.csv')
eruptions <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-12/eruptions.csv')
events <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-12/events.csv')
head(volcano) %>% data.frame()
head(eruptions) %>% data.frame()
head(events) %>% data.frame()
obs<-eruptions %>% filter(evidence_method_dating == 'Historical Observations' & start_year > 1800) %>%
select(volcano_name, volcano_number, vei, start_year, end_year, latitude, longitude) %>%
group_by(volcano_name) %>% mutate(freq = length(volcano_name), max.vei = max(vei, na.rm=TRUE)) %>%
ungroup()
obs$region<-factor(obs$region)
plotter<-obs %>% filter(vei > 3 & freq > 10)
left<-ggplot(plotter, aes(volcano_name, start_year, fill = population_within_10_km, size=vei)) +
geom_point(alpha=0.5, shape=21,colour='black',stroke=1.2) +
coord_flip() +
labs(x='', y='') +
scale_size_area(breaks=c(4,5,6), trans='exp', max_size=30) +
scale_fill_gradient(na.value='white', low='#ffffcc', high='#800026') +
scale_y_continuous(breaks=seq(1800, 2020, 20)) +
scale_x_discrete(expand=c(0.05,0.05)) +
theme_classic() +
theme(legend.position = 'none',
panel.grid.major.y = element_line(),
plot.margin=unit(c(0.5, 0, 0, 0), 'cm'))
plotter2<-plotter %>% group_by(volcano_name, region) %>% summarise(freq = unique(freq))
right<-ggplot(plotter2) +
geom_bar(aes(volcano_name, freq, fill=region), stat='identity') +
geom_text(aes(x=volcano_name, y=freq, label = region, col=region), size=2,hjust = -0.1) +
coord_flip() +
labs(y = 'Number of eruptions since 1800', x = '') +
theme_classic() +
theme(axis.text.y = element_blank(), axis.ticks=element_blank(), legend.position = 'none',
plot.margin=unit(c(0.5, 0, 0, 0), 'cm')) +
scale_y_continuous(expand=c(0, 0), breaks=seq(0, 100, 25)) +
scale_x_discrete(expand=c(0.05,0.05))
cowplot::plot_grid(left, right, rel_widths = c(1, 0.3), nrow=1)
#
# ggplot(obs %>% filter(start_year > 1882 & !is.na(vei)), aes(country, start_year, fill=vei)) +
#           geom_tile() +
#           coord_flip() +
#           theme_bw()
#
# ggplot(obs %>% filter(start_year > 1882 & !is.na(vei)), aes(vei, start_year, group=volcano_name)) +
#   geom_line() +
#   coord_flip() +
#   theme_bw()
#
#
#
# ggplot(obs %>% filter(start_year > 1882 & !is.na(vei)), aes(longitude, latitude, col=start_year, size=vei)) +
#   geom_point(alpha=0.2) +
#   theme_bw()
#
# ggplot(obs, aes(longitude, latitude, col=freq, size=max.vei)) +
#   geom_point(alpha=0.2) +
#   theme_bw()+
#   scale_colour_gradient(high='red', low='white')
#
#
#
#
#
setwd('tidytuesday')
library(tidyverse); library(funk)
volcano <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-12/volcano.csv')
eruptions <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-12/eruptions.csv')
events <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-12/events.csv')
head(volcano) %>% data.frame()
head(eruptions) %>% data.frame()
head(events) %>% data.frame()
obs<-eruptions %>% filter(evidence_method_dating == 'Historical Observations' & start_year > 1800) %>%
select(volcano_name, volcano_number, vei, start_year, end_year, latitude, longitude) %>%
group_by(volcano_name) %>% mutate(freq = length(volcano_name), max.vei = max(vei, na.rm=TRUE)) %>%
ungroup()
obs<-left_join(obs, volcano) %>%
mutate(volcano_name = fct_reorder(volcano_name, longitude))
obs$region<-factor(obs$region)
plotter<-obs %>% filter(vei > 3 & freq > 10)
left<-ggplot(plotter, aes(volcano_name, start_year, fill = population_within_10_km, size=vei)) +
geom_point(alpha=0.5, shape=21,colour='black',stroke=1.2) +
coord_flip() +
labs(x='', y='') +
scale_size_area(breaks=c(4,5,6), trans='exp', max_size=30) +
scale_fill_gradient(na.value='white', low='#ffffcc', high='#800026') +
scale_y_continuous(breaks=seq(1800, 2020, 20)) +
scale_x_discrete(expand=c(0.05,0.05)) +
theme_classic() +
theme(legend.position = 'none',
panel.grid.major.y = element_line(),
plot.margin=unit(c(0.5, 0, 0, 0), 'cm'))
plotter2<-plotter %>% group_by(volcano_name, region) %>% summarise(freq = unique(freq))
right<-ggplot(plotter2) +
geom_bar(aes(volcano_name, freq, fill=region), stat='identity') +
geom_text(aes(x=volcano_name, y=freq, label = region, col=region), size=2,hjust = -0.1) +
coord_flip() +
labs(y = 'Number of eruptions since 1800', x = '') +
theme_classic() +
theme(axis.text.y = element_blank(), axis.ticks=element_blank(), legend.position = 'none',
plot.margin=unit(c(0.5, 0, 0, 0), 'cm')) +
scale_y_continuous(expand=c(0, 0), breaks=seq(0, 100, 25)) +
scale_x_discrete(expand=c(0.05,0.05))
cowplot::plot_grid(left, right, rel_widths = c(1, 0.3), nrow=1)
#
# ggplot(obs %>% filter(start_year > 1882 & !is.na(vei)), aes(country, start_year, fill=vei)) +
#           geom_tile() +
#           coord_flip() +
#           theme_bw()
#
# ggplot(obs %>% filter(start_year > 1882 & !is.na(vei)), aes(vei, start_year, group=volcano_name)) +
#   geom_line() +
#   coord_flip() +
#   theme_bw()
#
#
#
# ggplot(obs %>% filter(start_year > 1882 & !is.na(vei)), aes(longitude, latitude, col=start_year, size=vei)) +
#   geom_point(alpha=0.2) +
#   theme_bw()
#
# ggplot(obs, aes(longitude, latitude, col=freq, size=max.vei)) +
#   geom_point(alpha=0.2) +
#   theme_bw()+
#   scale_colour_gradient(high='red', low='white')
#
#
#
#
#
