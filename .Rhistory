{
yVal = yVals[ii]         # where to have horizontal bars
bins.wmin = dplyr::filter(dataComb, SpecCode == specForFig[ii])$wmin  # for this sp
bins.wmax = dplyr::filter(dataComb, SpecCode == specForFig[ii])$wmax
bins.wmid = dplyr::filter(dataComb, SpecCode == specForFig[ii])$wmid
# bins for which wmin >= target.wmax
bins.wmin.gt.tmax = dplyr::filter(dataComb, SpecCode == specForFig[ii])$wmin.gt.tmax
bins.wmin.gt.tmax.yn = ifelse(bins.wmin.gt.tmax,"Y", "N")
# bins for which wmax > target.wmin
bins.wmax.gt.tmin = dplyr::filter(dataComb, SpecCode == specForFig[ii])$wmax.gt.tmin
bins.wmax.gt.tmin.yn = ifelse(bins.wmax.gt.tmin,"Y", "N")
segments(y0 = yVal,
x0 = bins.wmin,
x1 = bins.wmax,
col=colSpec, lwd=thick)    # recycles col
# Bin break labels (cannot do , with vector for labels, it seems):
for(iiii in 1:length(bins.wmin))
{
text(x = bins.wmin[iiii],
y = yVal,
labels = bquote(paste(w[.(ii)*","*
.(dplyr::filter(dataComb, SpecCode == specForFig[ii])$j[iiii])])),
pos = 1,
offset = 0.03*thick,
cex = cex.sub)
}
# Do final wmax manually:
text(x = bins.wmax[length(bins.wmax)],
y = yVal,
labels = bquote(paste(w[.(ii)*","*
.(max(dplyr::filter(dataComb, SpecCode == specForFig[ii])$j)+1)])),
pos = 1,
offset = 0.03*thick,
cex = cex.sub)
# Put counts for each bin
text(x = bins.wmid,
y = yVal,
labels = f(dplyr::filter(dataComb, SpecCode == specForFig[ii])$number, ii+1),
# ii+1 happens to give 3 d.p.s for species 2 and 2 for species 1,
#  as needed on figure
pos = NULL,
offset = 0.03*thick,
cex = cex.sub*1.2)
# Whether to include in counts
eps = 0.23                  # Offset from wmid for Y's and N's
text(x = bins.wmid - eps,
y = yVal,
labels = bins.wmin.gt.tmax.yn,
pos = 3,
offset = 0.03*thick,
cex = cex.sub*1.2)
text(x = bins.wmid + eps,
y = yVal,
labels = bins.wmax.gt.tmin.yn,
pos = 3,
offset = 0.03*thick,
cex = cex.sub*1.2)
}
# Need w_1,24 manually, assumes this is the only one with j=23
text(x = dplyr::filter(dataComb, j==23)$wmax,
y = yVals[1],
labels = bquote(paste(w[.(1)*","*24])),
pos = 1,
offset = 0.03*thick,
cex = cex.sub)
dataRecommend.isd = dplyr::select(dataBin,
Year,
wmin,
wmax,
Number)
data.year.list = list()                # to save results for each year
diff.ivec = vector()                   # to save i that have any cumSum !=
# verify TODO
fullYears = sort(unique(dataBin$Year))
for(i in 1:length(fullYears))
{
data.year = dplyr::filter(dataRecommend.isd,
Year == fullYears[i])
data.year = dplyr::arrange(data.year,
desc(wmin))
sumNumber = sum(data.year$Number)
# data.year = dplyr::mutate(data.year,
#                          cumSum = cumsum(Number))
# This is wrong when we have two species with the same
#  length-weight coefficients in the same year, use countGTEwmin then change it to
#                          cumSum in one go TODO since clearer
# Have to do not with dplyr:
wmin.vec = data.year$wmin
wmax.vec = data.year$wmax
num.vec  = data.year$Number
countGTEwmin = rep(NA, length(num.vec)) # to do a manual count
lowCount = countGTEwmin
highCount = countGTEwmin
for(iii in 1:length(countGTEwmin))
{
countGTEwmin[iii]    = sum( (wmin.vec >= wmin.vec[iii]) * num.vec)
lowCount[iii]  = sum( (wmin.vec >= wmax.vec[iii]) * num.vec)
highCount[iii] = sum( (wmax.vec >  wmin.vec[iii]) * num.vec)
}
data.year = cbind(data.year,
"countGTEwmin" = countGTEwmin,
"lowCount" = lowCount,
"highCount" = highCount)
data.year = dplyr::tbl_df(data.year)
data.year.list[[i]] = data.year
}
xlim.global = c(min(dataRecommend.isd$wmin),
max(dataRecommend.isd$wmax))   # x-axis limits to be common for
# all plots
ISD_bin_plot()
for(i in 1:length(fullYears))
{
ISD_bin_plot(data.year = data.year.list[[i]],
b.MLE = dplyr::filter(MLEbins.res, Year == fullYears[i])$b,
b.confMin = dplyr::filter(MLEbins.res, Year ==
fullYears[i])$confMin,
b.confMax = dplyr::filter(MLEbins.res, Year ==
fullYears[i])$confMax,
year = fullYears[i],
xlim = xlim.global,
xmin = dplyr::filter(MLEbins.res, Year ==
fullYears[i])$xmin,
xmax = dplyr::filter(MLEbins.res, Year ==
fullYears[i])$xmax
)
}
?ISD_bin_plot
ls()
load("/Users/robins64/Documents/git_repos/sey-nutrition/data/clean/nutrient/sey_nutrient_clean_stirling.Rdata")
ls()
ls()
head(biom.sp)
head(mast)
load("/Users/robins64/Documents/git_repos/fish-indicators/02_curve_fit/data/curve_fit_ready_jarvis.rdata")
ls()
head(biom)
load("/Users/robins64/Documents/git_repos/fish-indicators/01_pre-processing/data/jarvis_spc.biomseTL.yr.rdata")
ls()
head(BIO)
load("/Users/robins64/Documents/git_repos/changing-mpas/results/biomass_model.Rdata")
ls()
ls()
head(catches)
head(packages)
head(packets)
head(trips)
head(species)
packets
ls()
head(results)
head(mgma)
head(mgam)
str(mgam)
str(results)
dbinom(6, 9, 0.5)
dbinom(6, 9, 0.2)
dbinom(6, 9, 0.9)
dbinom(6, 9000, 0.5)
dbinom(6, 6, 0.5)
dbinom(6, 12, 0.5)
dbinom(6, 12, 0.9)
dbinom(6, 12, 0.55)
dbinom(6, 12, 0.5)
# define grid
p_grid <- seq( from=0 , to=1 , length.out=20 )
p_grid
p_grid <- seq( from=0 , to=1 , length.out=20 )
# define prior
prior <- rep( 1 , 20 )
# compute likelihood at each value in grid
likelihood <- dbinom( 6 , size=9 , prob=p_grid )
# compute product of likelihood and prior
unstd.posterior <- likelihood * prior
# standardize the posterior, so it sums to 1
posterior <- unstd.posterior / sum(unstd.posterior)
plot( p_grid , posterior , type="b" ,
xlab="probability of water" , ylab="posterior probability" )
mtext( "20 points" )
p_grid <- seq( from=0 , to=1 , length.out=20 )
# define prior
prior <- rep( 1 , 20 )
# compute likelihood at each value in grid
likelihood <- dbinom( 6 , size=9 , prob=p_grid )
# compute product of likelihood and prior
unstd.posterior <- likelihood * prior
# standardize the posterior, so it sums to 1
posterior <- unstd.posterior / sum(unstd.posterior)
plot( p_grid , posterior , type="b" ,
xlab="probability of water" , ylab="posterior probability" )
mtext( "20 points" )
p_seq
p_grid
prior
dbinom(6, 9, 0.5)
dbinom(6, 9, 0.2)
dbinom(6, 9, 0.9)
6/9
dbinom(6, 9, 1)
dbinom(6, 9, 1)
dbinom(6, 9, prob=0)
6/9
p_grid <- seq( from=0 , to=1 , length.out=1000 )
# define prior
prior <- rep( 1 , 20 )
# compute likelihood at each value in grid
likelihood <- dbinom( 6 , size=9 , prob=p_grid )
# compute product of likelihood and prior
unstd.posterior <- likelihood * prior
# standardize the posterior, so it sums to 1
posterior <- unstd.posterior / sum(unstd.posterior)
plot( p_grid , posterior , type="b" ,
xlab="probability of water" , ylab="posterior probability" )
mtext( "20 points" )
likelihood
# define grid
p_grid <- seq( from=0 , to=1 , length.out=20 )
# define prior
prior <- rep( 1 , 20 )
# compute likelihood at each value in grid
likelihood <- dbinom( 6 , size=9 , prob=p_grid )
likelihood
## quadratic approximation
library(rethinking)
globe.qa <- quap(
alist(
W ~ dbinom( W+L ,p) , # binomial likelihood p ~ dunif(0,1) # uniform prior
), data=list(W=6,L=3) )
globe.qa <- quap(
alist(
W ~ dbinom( W+L ,p) , # binomial likelihood p ~ dunif(0,1) # uniform prior
), data=list(W=6,L=3) )
globe.qa <- quap(
alist(
W ~ dbinom( W+L ,p) , # binomial likelihood p ~ dunif(0,1) # uniform prior
), data=list(W=6,L=3) )
globe.qa <- quap(alist(
W ~ dbinom( W+L ,p) , # binomial likelihood
p ~ dunif(0,1) # uniform prior
), data=list(W=6,L=3) )
precis(globe.qa)
## Chapter2 - small worlds and large worlds
dbinom(6, 9, 0.5)
dbinom(6, 9, 1)
dbinom(6, 9, prob=0)
dbinom(6, 9000, 0.5)
dbinom(6, 6, 0.5)
dbinom(6, 12, 0.5)
## grid approximation
# define grid
p_grid <- seq( from=0 , to=1 , length.out=20 )
# define prior
prior <- rep( 1 , 20 )
for(i in 1:3){
# compute likelihood at each value in grid
if(i == 1){likelihood <- dbinom( 3 , size=3 , prob=p_grid )}
if(i == 2){likelihood <- dbinom( 3 , size=4 , prob=p_grid )}
if(i == 3){likelihood <- dbinom( 5 , size=7 , prob=p_grid )}
# compute product of likelihood and prior
unstd.posterior <- likelihood * prior
# standardize the posterior, so it sums to 1
posterior <- unstd.posterior / sum(unstd.posterior)
plot( p_grid , posterior , type="b" ,
xlab="probability of water" , ylab="posterior probability" , title='i')
}
warnings()
# compute likelihood at each value in grid
if(i == 1){likelihood <- dbinom( 3 , size=3 , prob=p_grid )}
# compute product of likelihood and prior
unstd.posterior <- likelihood * prior
# standardize the posterior, so it sums to 1
posterior <- unstd.posterior / sum(unstd.posterior)
plot( p_grid , posterior , type="b" ,
xlab="probability of water" , ylab="posterior probability" , title='i')
par(mfrow=c(1,3))
for(i in 1:3){
# compute likelihood at each value in grid
if(i == 1){likelihood <- dbinom( 3 , size=3 , prob=p_grid )}
if(i == 2){likelihood <- dbinom( 3 , size=4 , prob=p_grid )}
if(i == 3){likelihood <- dbinom( 5 , size=7 , prob=p_grid )}
# compute product of likelihood and prior
unstd.posterior <- likelihood * prior
# standardize the posterior, so it sums to 1
posterior <- unstd.posterior / sum(unstd.posterior)
plot( p_grid , posterior , type="b" ,
xlab="probability of water" , ylab="posterior probability" , main='i')
}
par(mfrow=c(1,3))
for(i in 1:3){
# compute likelihood at each value in grid
if(i == 1){likelihood <- dbinom( 3 , size=3 , prob=p_grid )}
if(i == 2){likelihood <- dbinom( 3 , size=4 , prob=p_grid )}
if(i == 3){likelihood <- dbinom( 5 , size=7 , prob=p_grid )}
# compute product of likelihood and prior
unstd.posterior <- likelihood * prior
# standardize the posterior, so it sums to 1
posterior <- unstd.posterior / sum(unstd.posterior)
plot( p_grid , posterior , type="b" ,
xlab="probability of water" , ylab="posterior probability" , main=i)
}
## problem 2M2
prior[prior < 0.5] <- 0
prior
## problem 2M2
prior[prior < 0.5] <- 0
prior
prior < 0.5
## problem 2M2
prior[p_grid < 0.5] <- 0
prior
for(i in 1:3){
# compute likelihood at each value in grid
if(i == 1){likelihood <- dbinom( 3 , size=3 , prob=p_grid )}
if(i == 2){likelihood <- dbinom( 3 , size=4 , prob=p_grid )}
if(i == 3){likelihood <- dbinom( 5 , size=7 , prob=p_grid )}
# compute product of likelihood and prior
unstd.posterior <- likelihood * prior
# standardize the posterior, so it sums to 1
posterior <- unstd.posterior / sum(unstd.posterior)
plot( p_grid , posterior , type="b" ,
xlab="probability of water" , ylab="posterior probability" , main=i)
}
vb_matches <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-19/vb_matches.csv', guess_max = 76000)
library(cowplot)
library(tidyverse)
head(vb_matches)
citr:::insert_citation()
vb <- vb %>% pivot_longer(names_to = 'winning_age', values_from = c(w_p1_age, w_p2_age))
vb <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-19/vb_matches.csv', guess_max = 76000)
vb <- vb %>% pivot_longer(names_to = 'winning_age', values_from = c(w_p1_age, w_p2_age))
View(vb)
?pivot_longer
vb <- vb %>% pivot_longer(c(w_p1_age, w_p2_age), names_to = 'winning_age')
# Get the Data
setwd('tidytuesday')
# vb <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-19/vb_matches.csv', guess_max = 76000)
library(tidyverse)
library(cowplot)
theme_set(theme_classic())
head(vb)
vb2<-vb %>% filter(circuit == 'FIVB') %>%
mutate(age_win = (w_p1_age + w_p2_age)/2,
age_lose = (l_p1_age + l_p2_age)/2,
hgt_win = (w_p1_hgt + w_p2_hgt)/2,
hgt_lose = (l_p1_hgt + l_p2_hgt)/2,
country_win = w_p1_country,
country_lose = l_p1_country) %>%
select(country, year, date, match_num, w_p1_country,
age_win, age_lose, hgt_win, hgt_lose,
country_win, country_lose)
vb_avg<-vb2 %>% group_by(year) %>%
summarise(
age_win = mean(age_win, na.rm=TRUE), age_lose = mean(age_lose, na.rm=TRUE),
hgt_win = mean(hgt_win, na.rm=TRUE), hgt_lose = mean(hgt_lose, na.rm=TRUE))
vb_nation<-vb2 %>% group_by(country_win) %>%
count() %>% ungroup() %>%
mutate(country_win = fct_reorder(country_win, -n))
top<-ggplot(vb_avg) +
geom_point(aes(year, age_win), col='#1b9e77') +
geom_line(aes(year, age_win), col='#1b9e77') +
geom_point(aes(year, age_lose), col='#d95f02') +
geom_line(aes(year, age_lose), col='#d95f02') +
labs(x = '', y = 'yrs', subtitle='Winners are older (and getting younger)') +
scale_x_continuous(breaks=seq(2000, 2020,3)) +
theme(
plot.margin=margin(0.1, 0.1, -1, 0.1, 'cm'))
mid<-ggplot(vb_avg) +
geom_point(aes(year, hgt_win),col='#1b9e77') +
geom_line(aes(year, hgt_win),col='#1b9e77') +
geom_point(aes(year, hgt_lose), col='#d95f02') +
geom_line(aes(year, hgt_lose), col='#d95f02') +
labs(x = '', y = 'cm', subtitle='Winners are taller (and getting taller)') +
scale_x_continuous(breaks=seq(2000, 2020,3)) +
theme(plot.margin=margin(-1, 0.1, 0, 0.1, 'cm'))
bot<-ggplot(vb_nation %>% filter(n > 1000), aes(country_win, n)) +
# geom_bar(stat='identity') +
geom_flag(size = 10) +
labs(x = '', y = '',subtitle='Winning nations') +
scale_x_discrete(labels=NULL, expand=c(0,0)) +
scale_y_continuous(labels=scales::comma, expand=c(0,0)) +
theme(axis.ticks = element_blank())
pdf(file='volleyball.pdf', height=5, width=7)
l<-plot_grid(top, mid, nrow=2, align='hv')
plot_grid(l, bot, ncol=2)
dev.off()
# Get the Data
setwd('tidytuesday')
vb <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-19/vb_matches.csv', guess_max = 76000)
library(tidyverse)
library(cowplot)
theme_set(theme_classic())
head(vb)
vb2<-vb %>% filter(circuit == 'FIVB') %>%
mutate(age_win = (w_p1_age + w_p2_age)/2,
age_lose = (l_p1_age + l_p2_age)/2,
hgt_win = (w_p1_hgt + w_p2_hgt)/2,
hgt_lose = (l_p1_hgt + l_p2_hgt)/2,
country_win = w_p1_country,
country_lose = l_p1_country) %>%
select(country, year, date, match_num, w_p1_country,
age_win, age_lose, hgt_win, hgt_lose,
country_win, country_lose)
vb_avg<-vb2 %>% group_by(year) %>%
summarise(
age_win = mean(age_win, na.rm=TRUE), age_lose = mean(age_lose, na.rm=TRUE),
hgt_win = mean(hgt_win, na.rm=TRUE), hgt_lose = mean(hgt_lose, na.rm=TRUE))
vb_nation<-vb2 %>% group_by(country_win) %>%
count() %>% ungroup() %>%
mutate(country_win = fct_reorder(country_win, -n))
top<-ggplot(vb_avg) +
geom_point(aes(year, age_win), col='#1b9e77') +
geom_line(aes(year, age_win), col='#1b9e77') +
geom_point(aes(year, age_lose), col='#d95f02') +
geom_line(aes(year, age_lose), col='#d95f02') +
labs(x = '', y = 'yrs', subtitle='Winners are older (and getting younger)') +
scale_x_continuous(breaks=seq(2000, 2020,3)) +
theme(
plot.margin=margin(0.1, 0.1, -1, 0.1, 'cm'))
mid<-ggplot(vb_avg) +
geom_point(aes(year, hgt_win),col='#1b9e77') +
geom_line(aes(year, hgt_win),col='#1b9e77') +
geom_point(aes(year, hgt_lose), col='#d95f02') +
geom_line(aes(year, hgt_lose), col='#d95f02') +
labs(x = '', y = 'cm', subtitle='Winners are taller (and getting taller)') +
scale_x_continuous(breaks=seq(2000, 2020,3)) +
theme(plot.margin=margin(-1, 0.1, 0, 0.1, 'cm'))
bot<-ggplot(vb_nation %>% filter(n > 1000), aes(country_win, n)) +
# geom_bar(stat='identity') +
geom_flag(size = 10) +
labs(x = '', y = '',subtitle='Winning nations') +
scale_x_discrete(labels=NULL, expand=c(0,0)) +
scale_y_continuous(labels=scales::comma, expand=c(0,0)) +
theme(axis.ticks = element_blank())
pdf(file='volleyball.pdf', height=5, width=7)
l<-plot_grid(top, mid, nrow=2, align='hv')
plot_grid(l, bot, ncol=2)
dev.off()
install.packages('ggflags')
install.packages('ggimage')
library(ggimage)
# Get the Data
setwd('tidytuesday')
vb <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-19/vb_matches.csv', guess_max = 76000)
library(tidyverse)
library(cowplot)
library(ggimage)
theme_set(theme_classic())
head(vb)
vb2<-vb %>% filter(circuit == 'FIVB') %>%
mutate(age_win = (w_p1_age + w_p2_age)/2,
age_lose = (l_p1_age + l_p2_age)/2,
hgt_win = (w_p1_hgt + w_p2_hgt)/2,
hgt_lose = (l_p1_hgt + l_p2_hgt)/2,
country_win = w_p1_country,
country_lose = l_p1_country) %>%
select(country, year, date, match_num, w_p1_country,
age_win, age_lose, hgt_win, hgt_lose,
country_win, country_lose)
vb_avg<-vb2 %>% group_by(year) %>%
summarise(
age_win = mean(age_win, na.rm=TRUE), age_lose = mean(age_lose, na.rm=TRUE),
hgt_win = mean(hgt_win, na.rm=TRUE), hgt_lose = mean(hgt_lose, na.rm=TRUE))
vb_nation<-vb2 %>% group_by(country_win) %>%
count() %>% ungroup() %>%
mutate(country_win = fct_reorder(country_win, -n))
top<-ggplot(vb_avg) +
geom_point(aes(year, age_win), col='#1b9e77') +
geom_line(aes(year, age_win), col='#1b9e77') +
geom_point(aes(year, age_lose), col='#d95f02') +
geom_line(aes(year, age_lose), col='#d95f02') +
labs(x = '', y = 'yrs', subtitle='Winners are older (and getting younger)') +
scale_x_continuous(breaks=seq(2000, 2020,3)) +
theme(
plot.margin=margin(0.1, 0.1, -1, 0.1, 'cm'))
mid<-ggplot(vb_avg) +
geom_point(aes(year, hgt_win),col='#1b9e77') +
geom_line(aes(year, hgt_win),col='#1b9e77') +
geom_point(aes(year, hgt_lose), col='#d95f02') +
geom_line(aes(year, hgt_lose), col='#d95f02') +
labs(x = '', y = 'cm', subtitle='Winners are taller (and getting taller)') +
scale_x_continuous(breaks=seq(2000, 2020,3)) +
theme(plot.margin=margin(-1, 0.1, 0, 0.1, 'cm'))
bot<-ggplot(vb_nation %>% filter(n > 1000), aes(country_win, n)) +
# geom_bar(stat='identity') +
geom_flag(size = 10) +
labs(x = '', y = '',subtitle='Winning nations') +
scale_x_discrete(labels=NULL, expand=c(0,0)) +
scale_y_continuous(labels=scales::comma, expand=c(0,0)) +
theme(axis.ticks = element_blank())
pdf(file='volleyball.pdf', height=5, width=7)
l<-plot_grid(top, mid, nrow=2, align='hv')
plot_grid(l, bot, ncol=2)
dev.off()
dev.off()
bot
?geom_flag
library(tidyverse)
## tidytuesday for use-R group. 24th Jan 2024
## James Robinson
tuesdata <- tidytuesdayR::tt_load(2024, week = 2)
canada_births_1991_2022 <- tuesdata$canada_births_1991_2022
nhl_player_births <- tuesdata$nhl_player_births
nhl_rosters <- tuesdata$nhl_rosters
nhl_teams <- tuesdata$nhl_teams
head(tuesdata)
str(tuesdata)
head(nhl_teams)
head(nhl_rosters)
births<-nhl_rosters %>% group_by(team_code, season, position_code, birth_country) %>%
summarise(b = mean(birthdate))
births<-nhl_rosters %>% group_by(team_code, season, position_code, birth_country) %>%
summarise(b = mean(birth_date))
ggplot(births, aes(season, b, col=birth_country)) + geom_point()
